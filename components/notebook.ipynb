{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a05e62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtalib\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_all_ta_features\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mta\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dropna\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'talib'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import talib\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to fetch stock data\n",
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "# Function to calculate all technical indicators\n",
    "def calculate_indicators(df):\n",
    "    # ADX\n",
    "    df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    \n",
    "    # MACD\n",
    "    df['MACD'], df['MACD_Signal'], df['MACD_Hist'] = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    \n",
    "    # Hull Moving Average\n",
    "    def hull_moving_average(df, period):\n",
    "        wma_half = df['Close'].rolling(window=int(period/2)).apply(lambda x: ((np.arange(0, int(period/2)) + 1)*x).sum()/(np.arange(0, int(period/2)) + 1).sum(), raw=True)\n",
    "        wma_full = df['Close'].rolling(window=period).apply(lambda x: ((np.arange(0, period) + 1)*x).sum()/(np.arange(0, period) + 1).sum(), raw=True)\n",
    "        hma = 2 * wma_half - wma_full\n",
    "        hma = hma.rolling(window=int(np.sqrt(period))).mean()\n",
    "        return hma\n",
    "    df['HMA_9'] = hull_moving_average(df, 9)\n",
    "    \n",
    "    # Ichimoku Cloud\n",
    "    tenkan_period = 9\n",
    "    kijun_period = 26\n",
    "    senkou_span_b_period = 52\n",
    "    df['Tenkan_Sen'] = (df['High'].rolling(window=tenkan_period).max() + df['Low'].rolling(window=tenkan_period).min()) / 2\n",
    "    df['Kijun_Sen'] = (df['High'].rolling(window=kijun_period).max() + df['Low'].rolling(window=kijun_period).min()) / 2\n",
    "    df['Senkou_Span_A'] = ((df['Tenkan_Sen'] + df['Kijun_Sen']) / 2).shift(kijun_period)\n",
    "    df['Senkou_Span_B'] = ((df['High'].rolling(window=senkou_span_b_period).max() + df['Low'].rolling(window=senkou_span_b_period).min()) / 2).shift(kijun_period)\n",
    "    \n",
    "    # Aroon Indicator\n",
    "    df['Aroon_Up'], df['Aroon_Down'] = talib.AROON(df['High'], df['Low'], timeperiod=14)\n",
    "    \n",
    "    # Guppy MMA (using multiple EMAs)\n",
    "    periods = [3, 5, 8, 10, 12, 15, 30, 35, 40, 45, 50, 60]\n",
    "    for period in periods:\n",
    "        df[f'EMA_{period}'] = talib.EMA(df['Close'], timeperiod=period)\n",
    "    \n",
    "    # RSI\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "    \n",
    "    # Stochastic RSI\n",
    "    def stoch_rsi(df, period=14, smoothK=3, smoothD=3):\n",
    "        rsi = talib.RSI(df['Close'], timeperiod=period)\n",
    "        stochrsi = (rsi - rsi.rolling(period).min()) / (rsi.rolling(period).max() - rsi.rolling(period).min())\n",
    "        stochrsi_K = stochrsi.rolling(smoothK).mean()\n",
    "        stochrsi_D = stochrsi_K.rolling(smoothD).mean()\n",
    "        return stochrsi_K, stochrsi_D\n",
    "    df['Stoch_RSI_K'], df['Stoch_RSI_D'] = stoch_rsi(df)\n",
    "    \n",
    "    # Momentum\n",
    "    df['Momentum'] = talib.MOM(df['Close'], timeperiod=10)\n",
    "    \n",
    "    # ROC\n",
    "    df['ROC'] = talib.ROC(df['Close'], timeperiod=10)\n",
    "    \n",
    "    # TRIX\n",
    "    df['TRIX'] = talib.TRIX(df['Close'], timeperiod=15)\n",
    "    \n",
    "    # TSI\n",
    "    def tsi(df, long=25, short=13):\n",
    "        diff = df['Close'].diff(1)\n",
    "        abs_diff = diff.abs()\n",
    "        \n",
    "        ema_diff = diff.ewm(span=short, adjust=False).mean()\n",
    "        ema_abs_diff = abs_diff.ewm(span=short, adjust=False).mean()\n",
    "        \n",
    "        ema_ema_diff = ema_diff.ewm(span=long, adjust=False).mean()\n",
    "        ema_ema_abs_diff = ema_abs_diff.ewm(span=long, adjust=False).mean()\n",
    "        \n",
    "        tsi = 100 * (ema_ema_diff / ema_ema_abs_diff)\n",
    "        return tsi\n",
    "    df['TSI'] = tsi(df)\n",
    "    \n",
    "    # Connors RSI\n",
    "    def connors_rsi(df, rsi_period=3, streak_period=2, pct_rank_period=100):\n",
    "        # RSI\n",
    "        rsi = talib.RSI(df['Close'], timeperiod=rsi_period)\n",
    "        \n",
    "        # Up/Down Streak\n",
    "        streak = np.where(df['Close'].diff() > 0, 1, np.where(df['Close'].diff() < 0, -1, 0))\n",
    "        streak_rsi = talib.RSI(pd.Series(streak, index=df.index), timeperiod=streak_period)\n",
    "        \n",
    "        # Percent Rank\n",
    "        pct_rank = df['Close'].rolling(pct_rank_period).apply(lambda x: (x[-1] > x).mean())\n",
    "        \n",
    "        # Connors RSI\n",
    "        connors = (rsi + streak_rsi + pct_rank) / 3\n",
    "        return connors\n",
    "    df['Connors_RSI'] = connors_rsi(df)\n",
    "    \n",
    "    # Fisher Transform\n",
    "    def fisher_transform(df, period=10):\n",
    "        high, low = df['High'], df['Low']\n",
    "        median_price = (high + low) / 2\n",
    "        max_high = high.rolling(period).max()\n",
    "        min_low = low.rolling(period).min()\n",
    "        \n",
    "        normalized = (2 * ((median_price - min_low) / (max_high - min_low))) - 1\n",
    "        normalized = normalized.clip(-0.999, 0.999)\n",
    "        \n",
    "        fisher = 0.5 * np.log((1 + normalized) / (1 - normalized))\n",
    "        return fisher\n",
    "    df['Fisher_Transform'] = fisher_transform(df)\n",
    "    \n",
    "    # OBV\n",
    "    df['OBV'] = talib.OBV(df['Close'], df['Volume'])\n",
    "    \n",
    "    # Accumulation/Distribution\n",
    "    df['ADL'] = talib.AD(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "    \n",
    "    # MFI\n",
    "    df['MFI'] = talib.MFI(df['High'], df['Low'], df['Close'], df['Volume'], timeperiod=14)\n",
    "    \n",
    "    # CMF\n",
    "    def cmf(df, period=20):\n",
    "        mfv = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low'])\n",
    "        mfv = mfv * df['Volume']\n",
    "        cmf = mfv.rolling(period).sum() / df['Volume'].rolling(period).sum()\n",
    "        return cmf\n",
    "    df['CMF'] = cmf(df)\n",
    "    \n",
    "    # VWAP\n",
    "    def calculate_vwap(df):\n",
    "        vwap = (df['Volume'] * (df['High'] + df['Low'] + df['Close']) / 3).cumsum() / df['Volume'].cumsum()\n",
    "        return vwap\n",
    "    df['VWAP'] = calculate_vwap(df)\n",
    "    \n",
    "    # VWMA\n",
    "    def vwma(df, period=20):\n",
    "        vwma = (df['Close'] * df['Volume']).rolling(period).sum() / df['Volume'].rolling(period).sum()\n",
    "        return vwma\n",
    "    df['VWMA_20'] = vwma(df)\n",
    "    \n",
    "    # ATR\n",
    "    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = talib.BBANDS(df['Close'], timeperiod=20)\n",
    "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
    "    df['BB_%B'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "    \n",
    "    # Choppiness Index\n",
    "    def choppiness_index(df, period=14):\n",
    "        atr_sum = df['ATR'].rolling(period).sum()\n",
    "        high_max = df['High'].rolling(period).max()\n",
    "        low_min = df['Low'].rolling(period).min()\n",
    "        ci = 100 * np.log10(atr_sum / (high_max - low_min)) / np.log10(period)\n",
    "        return ci\n",
    "    df['Choppiness_Index'] = choppiness_index(df)\n",
    "    \n",
    "    # RVI\n",
    "    def rvi(df, period=14):\n",
    "        close_diff = df['Close'].diff()\n",
    "        high_diff = df['High'].diff()\n",
    "        low_diff = df['Low'].diff()\n",
    "        \n",
    "        num = (close_diff + 2 * high_diff + 2 * low_diff).rolling(period).sum()\n",
    "        den = (4 * high_diff.abs() + 4 * low_diff.abs()).rolling(period).sum()\n",
    "        rvi = num / den\n",
    "        return rvi\n",
    "    df['RVI'] = rvi(df)\n",
    "    \n",
    "    # Historical Volatility\n",
    "    df['Historical_Volatility'] = df['Close'].pct_change().rolling(20).std() * np.sqrt(252)\n",
    "    \n",
    "    # Standard Deviation\n",
    "    df['Std_Dev_20'] = df['Close'].rolling(20).std()\n",
    "    \n",
    "    # Donchian Channel\n",
    "    df['Donchian_High'] = df['High'].rolling(20).max()\n",
    "    df['Donchian_Low'] = df['Low'].rolling(20).min()\n",
    "    df['Donchian_Middle'] = (df['Donchian_High'] + df['Donchian_Low']) / 2\n",
    "    \n",
    "    # Pivot Points\n",
    "    def calculate_pivot_points(df):\n",
    "        prev_day = df.shift(1)\n",
    "        df['Pivot'] = (prev_day['High'] + prev_day['Low'] + prev_day['Close']) / 3\n",
    "        df['R1'] = 2 * df['Pivot'] - prev_day['Low']\n",
    "        df['S1'] = 2 * df['Pivot'] - prev_day['High']\n",
    "        df['R2'] = df['Pivot'] + (prev_day['High'] - prev_day['Low'])\n",
    "        df['S2'] = df['Pivot'] - (prev_day['High'] - prev_day['Low'])\n",
    "        df['R3'] = df['Pivot'] + 2 * (prev_day['High'] - prev_day['Low'])\n",
    "        df['S3'] = df['Pivot'] - 2 * (prev_day['High'] - prev_day['Low'])\n",
    "        return df\n",
    "    df = calculate_pivot_points(df)\n",
    "    \n",
    "    # Fibonacci Levels\n",
    "    def calculate_fib_levels(df):\n",
    "        prev_day = df.shift(1)\n",
    "        high = prev_day['High'].iloc[-1]\n",
    "        low = prev_day['Low'].iloc[-1]\n",
    "        df['Fib_0'] = high\n",
    "        df['Fib_0.236'] = high - (high - low) * 0.236\n",
    "        df['Fib_0.382'] = high - (high - low) * 0.382\n",
    "        df['Fib_0.5'] = high - (high - low) * 0.5\n",
    "        df['Fib_0.618'] = high - (high - low) * 0.618\n",
    "        df['Fib_1'] = low\n",
    "        return df\n",
    "    df = calculate_fib_levels(df)\n",
    "    \n",
    "    # Darvas Box\n",
    "    def darvas_box(df, period=5):\n",
    "        df['Darvas_High'] = df['High'].rolling(period).max()\n",
    "        df['Darvas_Low'] = df['Low'].rolling(period).min()\n",
    "        return df\n",
    "    df = darvas_box(df)\n",
    "    \n",
    "    # William Fractal\n",
    "    def william_fractal(df):\n",
    "        # Bullish Fractal\n",
    "        fractal_bull = (df['High'] > df['High'].shift(1)) & \\\n",
    "                      (df['High'] > df['High'].shift(2)) & \\\n",
    "                      (df['High'] > df['High'].shift(-1)) & \\\n",
    "                      (df['High'] > df['High'].shift(-2))\n",
    "        \n",
    "        # Bearish Fractal\n",
    "        fractal_bear = (df['Low'] < df['Low'].shift(1)) & \\\n",
    "                       (df['Low'] < df['Low'].shift(2)) & \\\n",
    "                       (df['Low'] < df['Low'].shift(-1)) & \\\n",
    "                       (df['Low'] < df['Low'].shift(-2))\n",
    "        \n",
    "        df['Fractal_Bull'] = fractal_bull.astype(int)\n",
    "        df['Fractal_Bear'] = fractal_bear.astype(int)\n",
    "        return df\n",
    "    df = william_fractal(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to create features and target\n",
    "def prepare_data(df, forecast_days=15):\n",
    "    # Create target (future price)\n",
    "    df['Target'] = df['Close'].shift(-forecast_days)\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(['Target'], axis=1)\n",
    "    y = df['Target']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to train model\n",
    "def train_model(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_pred = model.predict(X_train_scaled)\n",
    "    test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "    \n",
    "    print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.2f}\")\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_future(model, scaler, df, forecast_days=15):\n",
    "    # Use the most recent data point\n",
    "    last_data = df.iloc[-1:].copy()\n",
    "    \n",
    "    # Prepare features for prediction (without target)\n",
    "    X_pred = last_data.drop(['Target'], axis=1, errors='ignore')\n",
    "    X_pred_scaled = scaler.transform(X_pred)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_pred_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Get ticker symbol from user\n",
    "    ticker = input(\"Enter stock ticker (e.g., AAPL): \").upper()\n",
    "    \n",
    "    # Define date range (last 5 years)\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=5*365)\n",
    "    \n",
    "    # Get stock data\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    stock_data = get_stock_data(ticker, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    if stock_data.empty:\n",
    "        print(\"No data found for this ticker.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate all indicators\n",
    "    print(\"Calculating technical indicators...\")\n",
    "    stock_data = calculate_indicators(stock_data)\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    X, y = prepare_data(stock_data)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model, scaler = train_model(X, y)\n",
    "    \n",
    "    # Make predictions for next 15 days\n",
    "    print(\"\\n15-day price prediction:\")\n",
    "    predictions = []\n",
    "    current_data = stock_data.copy()\n",
    "    \n",
    "    for day in range(1, 16):\n",
    "        # Predict next day\n",
    "        next_price = predict_future(model, scaler, current_data)\n",
    "        predictions.append(next_price)\n",
    "        \n",
    "        # Create a new row for the predicted day\n",
    "        new_row = current_data.iloc[-1:].copy()\n",
    "        new_row.index = [new_row.index[0] + timedelta(days=1)]\n",
    "        new_row['Close'] = next_price\n",
    "        \n",
    "        # Update some basic values (simplistic approach)\n",
    "        new_row['Open'] = current_data['Close'].iloc[-1]\n",
    "        new_row['High'] = max(new_row['Open'], next_price)\n",
    "        new_row['Low'] = min(new_row['Open'], next_price)\n",
    "        new_row['Volume'] = current_data['Volume'].rolling(5).mean().iloc[-1]  # Use average volume\n",
    "        \n",
    "        # Append to dataframe\n",
    "        current_data = pd.concat([current_data, new_row])\n",
    "        \n",
    "        # Recalculate indicators for the new row\n",
    "        current_data = calculate_indicators(current_data)\n",
    "        \n",
    "        # Print prediction\n",
    "        print(f\"Day {day}: {next_price:.2f}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(stock_data.index[-60:], stock_data['Close'][-60:], label='Historical Prices')\n",
    "    future_dates = [stock_data.index[-1] + timedelta(days=i) for i in range(1, 16)]\n",
    "    plt.plot(future_dates, predictions, 'r-', label='Predicted Prices')\n",
    "    plt.title(f'{ticker} 15-Day Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f001437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9b25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
